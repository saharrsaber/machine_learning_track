{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering for Machine Learning in Python\n",
    "\n",
    "It's a course in [DataCamp Machine Learning in Python Track](https://learn.datacamp.com/career-tracks/machine-learning-scientist-with-python?version=1). Robert O'Callaghan is the instructor. He is The Director of Data Science @ Ordergroove \n",
    "\n",
    "the first part of this notebook contains the main Algorithms I learned from [the course](https://learn.datacamp.com/courses/feature-engineering-for-machine-learning-in-python).  The second is how I implemented these algorithms into real-world Datasets\n",
    " \n",
    "## Part 1: Main Algorithms\n",
    "### Ch1. Creating Features\n",
    "* **To select columns with specific type: <br>**\n",
    "&emsp; df.select_dtypes(include = ['int']) <br>\n",
    "* **when you deal with categoriacal not ordinal variables: <br>**\n",
    "&emsp; dummy variables is better than replacing the categories with numbers <br>\n",
    "&emsp; pd.get_dummies(df, columns=['Country'], perfix = 'C', drop_first = True) <br>\n",
    "&emsp; to avoid having so many cols; get value_counts and change any label that occurs less than a thershold to 'Others'\n",
    "* **To bin numeric variables <br>**\n",
    "&emsp; df['age_group'] = pd.cut(df['age'], bins = [-np.inf, 21, 60, np.inf], labels = ['students', 'workers', 'retired']\n",
    "\n",
    "\n",
    "### Ch2. Dealing with Messy Data\n",
    "### Ch3. Conforming to Statistical Assumptions\n",
    "* **MinMaxScalar  <br>**\n",
    "&emsp; consider the MIN value as 0 and MAX value as 1-> maps from 0 to 1\n",
    "<br>&emsp; adv: remain the sahpe of distribustion as it is\n",
    "<br>&emsp; dis: if in the test set value > MAX or calue < MIN -> unforeseen result\n",
    "\n",
    "* **StandardScalar**\n",
    "<br>&emsp; adv: scalable\n",
    "<br>&emsp; dis: changes the sahpe of distribustion \n",
    "\n",
    "### Ch4. Dealing with Text Data\n",
    "* **Remove non letter characters**\n",
    "<br>&emsp; df['text'].str.replace(\"[^a-zA-Z]\", \" \")\n",
    "* **lowercase all letters**\n",
    "<br>&emsp;  df['text'].str.lower()\n",
    "* **bag-of-words**\n",
    " * **CountVectorizer**\n",
    "<br>&emsp; cv = CountVectorizer(min_df= 0.1, max_df= 0.9)\n",
    "<br>&emsp; &emsp; min_df--> remove rarely used words\n",
    "<br>&emsp; &emsp; min_df--> remove mostly used words(and, the, a, an , ..)\n",
    "<br>&emsp; new_text = cv.fit_transform(text).toarray() -> to covert the spare array to normal array\n",
    "<br>&emsp; df_text = pd.DataFrame(new_text, columns = cv.get_feature_names()) -> to connect words with thier freqs\n",
    " * **tfidfvectorizer**\n",
    "<br>&emsp; tfidf = tfidfvectorizer(word_stop='english') \n",
    "<br>&emsp; &emsp; word_stop-> remove common used words in this language(and, of, the, ...)\n",
    "* **N-grams**\n",
    "<br>&emsp; add ngram_range when intializing your vectorizier\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
